{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "boto3==1.12.36\n",
    "botocore==1.15.36\n",
    "certifi==2020.4.5.1\n",
    "chardet==3.0.4\n",
    "click==7.1.1\n",
    "docutils==0.15.2\n",
    "filelock==3.0.12\n",
    "idna==2.9\n",
    "jmespath==0.9.5\n",
    "joblib==0.14.1\n",
    "jsonlines==1.2.0\n",
    "numpy==1.18.2\n",
    "pandas==1.0.3\n",
    "python-dateutil==2.8.1\n",
    "regex==2020.4.4\n",
    "requests==2.23.0\n",
    "s3transfer==0.3.3\n",
    "sacremoses==0.0.38\n",
    "scikit-learn==0.22.2.post1\n",
    "scipy==1.4.1\n",
    "scispacy==0.2.5\n",
    "https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.5/en_core_sci_sm-0.2.5.tar.gz\n",
    "sentencepiece==0.1.85\n",
    "six==1.14.0\n",
    "tokenizers==0.5.2\n",
    "torch==1.5.0\n",
    "tqdm==4.45.0\n",
    "transformers==2.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading SciFact database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wget https://scifact.s3-us-west-2.amazonaws.com/release/latest/data.tar.gz\n",
    "tar -xvf data.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import jsonlines\n",
    "import os\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import get_cosine_schedule_with_warmup, RobertaTokenizer, RobertaForSequenceClassification\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device \"{device}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SciFactRationaleSelectionDataset(Dataset):\n",
    "    def __init__(self, corpus: str, dataset: str, abstracts):\n",
    "        self.samples = []\n",
    "        abstract_retrieval = jsonlines.open(abstracts)\n",
    "        dataset = jsonlines.open(dataset)\n",
    "        corpus = {doc['doc_id']: doc for doc in jsonlines.open(corpus)}\n",
    "        for data, retrieval in tqdm(list(zip(dataset, abstract_retrieval))):\n",
    "            assert data['id'] == retrieval['id']\n",
    "            # Adding docs from reduced abstract method 1 and cited docs\n",
    "            docs = set()\n",
    "            for i in retrieval['retrieved_doc_ids']:\n",
    "                if(len(docs)>=4):\n",
    "                break\n",
    "                docs.add(i)\n",
    "            for i in retrieval['cited_doc_ids']:\n",
    "                if(len(docs)>=4):\n",
    "                break\n",
    "                docs.add(i)\n",
    "            for doc_id in docs:\n",
    "                doc_id = str(doc_id)\n",
    "                doc = corpus[int(doc_id)]\n",
    "                #if the doc is correctly retrieved\n",
    "                if doc_id in list(data['evidence'].keys()):\n",
    "                    evidence_sentence_idx = {s for es in data['evidence'][doc_id] for s in es['sentences']}\n",
    "                else:\n",
    "                    evidence_sentence_idx = {}\n",
    "                for i, sentence in enumerate(doc['abstract']):\n",
    "                    self.samples.append({\n",
    "                        'claim': data['claim'],\n",
    "                        'sentence': sentence,\n",
    "                        'evidence': i in evidence_sentence_idx\n",
    "                    })\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "\n",
    "def encode(claims: List[str], sentences: List[str]):\n",
    "    encoded_dict = tokenizer.batch_encode_plus(\n",
    "        zip(sentences, claims),\n",
    "        pad_to_max_length=True,\n",
    "        return_tensors='pt')\n",
    "    if encoded_dict['input_ids'].size(1) > 512:\n",
    "        # Too long for the model. Truncate it\n",
    "        encoded_dict = tokenizer.batch_encode_plus(\n",
    "            zip(sentences, claims),\n",
    "            max_length=512,\n",
    "            truncation_strategy='only_first',\n",
    "            pad_to_max_length=True,\n",
    "            return_tensors='pt')\n",
    "    encoded_dict = {key: tensor.to(device) for key, tensor in encoded_dict.items()}\n",
    "    return encoded_dict\n",
    "\n",
    "def evaluate(model, dataset):\n",
    "    model.eval()\n",
    "    targets = []\n",
    "    outputs = []\n",
    "    with torch.no_grad():\n",
    "        for batch in DataLoader(dataset, batch_size=1):\n",
    "            encoded_dict = encode(batch['claim'], batch['sentence'])\n",
    "            logits = model(**encoded_dict)[0]\n",
    "            targets.extend(batch['evidence'].float().tolist())\n",
    "            outputs.extend(logits.argmax(dim=1).tolist())\n",
    "    return f1_score(targets, outputs, zero_division=0),\\\n",
    "           precision_score(targets, outputs, zero_division=0),\\\n",
    "           recall_score(targets, outputs, zero_division=0), \\\n",
    "           accuracy_score(targets, outputs), \\\n",
    "           balanced_accuracy_score(targets, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = './data/corpus.jsonl'\n",
    "claim_train = './data/claims_train.jsonl'\n",
    "claim_dev = './data/claims_dev.jsonl'\n",
    "# Predicted abstract retrieval files here\n",
    "abstract_train = './abstract_retrieval_Train.jsonl'\n",
    "abstract_dev = './abstract_retrieval_Dev.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = SciFactRationaleSelectionDataset(corpus, claim_train, abstract_train)\n",
    "devset = SciFactRationaleSelectionDataset(corpus, claim_dev, abstract_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('dmis-lab/biobert-large-cased-v1.1')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('dmis-lab/biobert-large-cased-v1.1').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([\n",
    "            {'params': model.bert.parameters(), 'lr': 5e-5},\n",
    "            {'params': model.classifier.parameters(), 'lr': 1e-3}])\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, 128, 50 * 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(50):\n",
    "    model.train()\n",
    "    t = tqdm(DataLoader(trainset, batch_size=1, shuffle=True))\n",
    "    for i, batch in enumerate(t):\n",
    "        encoded_dict = encode(batch['claim'], batch['sentence'])\n",
    "        loss, logits = model(**encoded_dict, labels=batch['evidence'].long().to(device))\n",
    "        loss.backward()\n",
    "        if (i + 1) % (128 // 1) == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            t.set_description(f'Epoch {e}, iter {i}, loss: {round(loss.item(), 4)}')\n",
    "    scheduler.step()\n",
    "    train_score = evaluate(model, trainset)\n",
    "    print(f'Epoch {e}, train f1: %.4f, precision: %.4f, recall: %.4f, acc: %.4f, balanced_acc: %.4f' % train_score)\n",
    "    dev_score = evaluate(model, devset)\n",
    "    print(f'Epoch {e}, dev f1: %.4f, precision: %.4f, recall: %.4f, acc: %.4f, balanced_acc: %.4f' % dev_score)\n",
    "    # Save\n",
    "    save_path = os.path.join('./saved_models', f'rationale_selection_epoch-{e}-f1-{int(dev_score[0] * 1e4)}')\n",
    "    os.makedirs(save_path)\n",
    "    tokenizer.save_pretrained(save_path)\n",
    "    model.save_pretrained(save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
